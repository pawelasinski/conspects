## 1. Общая структура и подсказки

- **Проверка доступных команд и опций**  
```bash
hdfs dfs -help
hdfs dfs -help <command>
```
  Пример: `hdfs dfs -help put` выведет список опций и примеров для команды `put`.

- **Просмотр версии**  
```bash
hadoop version
```

---

## 2. Работа с файлами и директориями

### Просмотр содержимого (LS)

- **Список содержимого директории**  
```bash
hdfs dfs -ls /path/to/directory
```
  Опция `-R` (рекурсивно):
```bash
hdfs dfs -ls -R /path/to/directory
```

- **Проверка информации о квотах и использовании**  
```bash
hdfs dfs -count -q /path/to/directory
```

---

Команда  позволяет вывести информацию об использовании HDFS в разрезе квот (quota). В отличие от простой  
```bash
hdfs dfs -count /path/to/directory
```
которая показывает только количество каталогов, количество файлов и суммарный объём данных, опция **`-q`** (quota) дополнительно выводит столбцы, связанные с квотами:  

1. **QUOTA** — лимит на количество **поддиректорий и файлов** (Directory Quota).  
2. **REM_QUOTA** — оставшийся «запас» по количеству (сколько ещё можно создать).  
3. **SPACE_QUOTA** — лимит на суммарный объём данных, который можно хранить в данной директории (Space Quota).  
4. **REM_SPACE_QUOTA** — оставшийся «запас» по объёму.  
5. **DIR_COUNT** — общее количество директорий (включая поддиректории).  
6. **FILE_COUNT** — количество файлов (и символических ссылок, если они поддерживаются).  
7. **CONTENT_SIZE** — суммарный размер контента в байтах (сколько реально занимает файловая структура в HDFS).  
8. **PATHNAME** — путь к директории.

То есть вывод будет содержать, помимо стандартных счётчиков (директорий, файлов и общего объёма), информацию о квотах (если они настроены в HDFS на этом пути). Если квоты не заданы (или не поддерживаются), соответствующие поля могут отображаться как `none`, `inf` или `-`.

Пример типичного вывода (колонки могут немного отличаться в разных версиях Hadoop):
```
QUOTA  REM_QUOTA  SPACE_QUOTA  REM_SPACE_QUOTA  DIR_COUNT  FILE_COUNT   CONTENT_SIZE  PATHNAME
none   inf        none         inf              107        13           72587175      /user/hive/warehouse
```
- **none** и **none** говорят о том, что квота по количеству объектов и квота по объёму не заданы.
- **inf** означает, что лимит не ограничен.

Таким образом, команда `-count -q` удобна, если нужно не только понять, сколько данных хранится в директории, но и есть ли установленные лимиты (quota) и насколько они уже израсходованы.  

---

Опция `-h` (human-readable) иногда поддерживается:
```bash
hdfs dfs -du -s -h /path/to/directory
```
  где `-du` показывает дисковое использование (disk usage).

### Создание и удаление директорий

- **Создание директории**  
```bash
hdfs dfs -mkdir /path/to/directory
```
  Опция `-p` создаёт промежуточные поддиректории, если их нет:
```bash
hdfs dfs -mkdir -p /path/to/directory/nested_directory
```

- **Удаление пустой директории**  
```bash
hdfs dfs -rmdir /path/to/directory
```
  Если нужно удалить непустую директорию (рекурсивно), используется команда `-rm -r`.

### Загрузка файлов в HDFS

- **Копирование файлов из локальной файловой системы в HDFS**  
```bash
hdfs dfs -put /path/to/local/file /path/to/HDFS/
```
  или
```bash
hdfs dfs -copyFromLocal /path/to/local/file /path/to/HDFS/
```
  - `-f` (force) может перезаписать файл при необходимости.

- **Перемещение файла из локальной ФС в HDFS (с удалением локального файла)**  
```bash
hdfs dfs -moveFromLocal /path/to/local/file /path/to/HDFS/
```

### Загрузка (выгрузка) файлов из HDFS

- **Скачивание файлов из HDFS в локальную ФС**  
```bash
hdfs dfs -get /path/to/HDFS/file /path/to/localhost
```
  или
```bash
hdfs dfs -copyToLocal /path/to/HDFS/file /path/to/local/directory
```

- **Перемещение файла из HDFS в локальную ФС (с удалением из HDFS)**  
```bash
hdfs dfs -moveToLocal /path/to/HDFS/file /path/to/local/directory
```
  (учтите, что команда может быть недоступна в некоторых сборках Hadoop)

### Удаление файлов

- **Удаление файла**  
```bash
hdfs dfs -rm /path/to/file
```
  - Опция `-skipTrash` удаляет файл, обходя корзину (Trash).
  - Опция `-r` удаляет директорию рекурсивно.

Пример:
```bash
hdfs dfs -rm -r -skipTrash /path/to/directory
```

### Просмотр содержимого файлов

- **Чтение файла напрямую из HDFS в stdout**  
```bash
hdfs dfs -cat /path/to/file
```
  Пример:
```bash
hdfs dfs -cat /user/hive/warehouse/table/000000_0
```

- **Просмотр первых N строк**  
```bash
hdfs dfs -head /path/to/file
```
  По умолчанию показываются первые 1К байт, в зависимости от версии можно указать `-n <число_строк>`.

- **Просмотр последних N строк**  
```bash
hdfs dfs -tail /path/to/file
```
  Обычно показывает последние 1К байт. В некоторых версиях есть опция `-f` (следить за обновлениями, как tail -f).

---

## 3. Управление правами, владельцами и репликацией

### Права доступа (chmod)

- **Изменение прав доступа**  
```bash
hdfs dfs -chmod <mode> /path/to/file/or/directory
```
  Пример:
```bash
hdfs dfs -chmod 755 /user/username/directory
```

### Владелец и группа (chown)

- **Изменение владельца (owner) и группы (group)**  
```bash
hdfs dfs -chown [owner][:[group]] /path/to/file
```
  Примеры:
```bash
# Изменить только владельца
hdfs dfs -chown newowner /path/to/file

# Изменить владельца и группу
hdfs dfs -chown newowner:newgroup /path/to/file
  ```

### Репликация и факторы дублирования (setrep)

- **Просмотр или изменение уровня репликации**  
```bash
# Установка фактора репликации для файла/директории
hdfs dfs -setrep -w <integer> /path/to/file/or/directory
```
  Параметр `-w` заставляет команду дождаться завершения операции репликации.

---

## 4. Полезные команды для диагностики и администрирования

### Проверка целостности (fsck)

- **Проверка HDFS на повреждения блоков**  
```bash
hdfs fsck /path/to/file/or/directory -files -blocks -locations
```
  - Параметры:
    - `-files` — показать файлы,
    - `-blocks` — показать блоки,
    - `-locations` — показать физические локации блоков.

### Тест существования объекта (test)

- **Проверка существования файла/директории**  
```bash
hdfs dfs -test -[e|d|f|s|z] /path/to/object
```
  Флаги:
  - `-e` — проверка, что файл/директория существует;
  - `-d` — проверка, что это директория;
  - `-f` — проверка, что это файл;
  - `-s` — проверка, что файл не пустой (non-zero);
  - `-z` — проверка, что файл пустой (zero length).

### Краткая информация о файле/директории

- **Команда `-stat`**  
```bash
hdfs dfs -stat "%r %y %F" /path/to/file
```
  Где:
  - `%r` — фактор репликации,
  - `%y` — время последней модификации,
  - `%F` — тип файла (FILE, DIRECTORY и т.д.).

### Копирование между кластерами (distcp)

Если у вас несколько Hadoop-кластеров и настроена сеть, то для копирования больших объёмов данных часто используют `distcp`. Это отдельный инструмент (команда):
```bash
hadoop distcp hdfs://namenode_src:8020/path hdfs://namenode_dest:8020/path
```
Позволяет параллельно копировать данные между кластерами, сохраняя структуру директорий и метаданные.

---

## 5. Работа с корзиной (Trash)

По умолчанию при удалении через `hdfs dfs -rm` файлы могут попадать в «корзину» (Trash).  
- **Очистка корзины**  
```bash
hdfs dfs -expunge
```
  Удалит файлы, чьё время хранения в корзине превысило заданный конфигурацией период (`fs.trash.interval` и `fs.trash.checkpoint.interval`).  

Если нужно удалить без помещения в корзину, используйте `-skipTrash`:
```bash
hdfs dfs -rm -skipTrash /path/to/file
```

---

## 6. Дополнительные советы и рекомендации

1. **Используйте алиасы**: часто удобно настроить сокращённые команды в `~/.bashrc`, например  
```bash
alias hls='hdfs dfs -ls'
alias hrm='hdfs dfs -rm'
```
   и т.д.

2. **Проверяйте права и владение**: если операция не удалась, возможно, у вас нет прав. Тогда либо используйте пользователя `hdfs` (если есть доступ через `sudo -u hdfs`), либо измените права.

3. **Следите за версиями**: в разных версиях Hadoop могут отличаться ключи и опции (особенно для таких команд, как `-head`, `-tail`, `-test` и `distcp`).

4. **Оптимизируйте передачу больших файлов**: если файлы очень большие, используйте:
   - `distcp` для копирования между кластерами,
   - или `-D dfs.client.block.write.replace-datanode-on-failure.policy=NEVER` в некоторых крайних случаях.

5. **Monitoring и Web UI**: помимо CLI, у HDFS есть веб-интерфейс (обычно на порту 50070 или 9870, в зависимости от версии), где можно просматривать статус NameNode, блоки, Health и др.